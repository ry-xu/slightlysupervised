{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import islice, cycle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# optimize for blog post\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    max_iters=10000,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    in_dim=28*28,\n",
    "    out_dim=10,\n",
    "    hidden_dims=[32, 32, 16],\n",
    "    pixels_allowed=[16, 32, 64, 128, 256, 512, 768],\n",
    ")\n",
    "config['eval_iters'] = config['max_iters'] // 10\n",
    "\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/mnist', download=True, train=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='data/mnist', download=True, train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "f\"{config['max_iters']/len(train_loader):.2f} Epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims, activation=F.gelu):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_layers = nn.ModuleList(\n",
    "            nn.Linear(i, o) for i, o in zip(dims[:-1], dims[1:])\n",
    "        )\n",
    "        self.act = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten in case\n",
    "\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.act(layer(x))\n",
    "        \n",
    "        return self.linear_layers[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(iterable, max_iters):\n",
    "    gen = islice(cycle(iterable), max_iters)\n",
    "    return tqdm(gen, total=max_iters)\n",
    "\n",
    "def eval(model, loss_fn):\n",
    "    model.eval()\n",
    "    metrics = defaultdict(lambda: 0)\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_ = model(x)\n",
    "            metrics['loss'] += loss_fn(y_, y).item() / len(val_loader)\n",
    "            metrics['accuracy'] += (y_.argmax(-1) == y).sum().item() / y.size(0) / len(val_loader)\n",
    "    model.train()\n",
    "    return dict(metrics)\n",
    "\n",
    "def train(model, optimizer=None, loss_fn=None, verbose=True):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for step, (x, y) in enumerate(loop(train_loader, config['max_iters'])):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (step + 1) % config['eval_iters'] == 0:\n",
    "            metrics = eval(model, loss_fn)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'step {step+1:{len(str(config[\"max_iters\"]))}d}:', end=' ')\n",
    "                print(' | '.join([f\"{metric}: {value:.4f}\" for metric, value in metrics.items()]))\n",
    "\n",
    "            for metric, value in metrics.items():\n",
    "                history[metric].append(value)\n",
    "            \n",
    "            history['steps'].append(step)\n",
    "    return dict(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot experiments for later\n",
    "\n",
    "def plot(experiment_names=None):\n",
    "    metric_names = ['loss', 'accuracy']\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metric_names), figsize=(5 * len(metric_names), 5))\n",
    "    axes = [axes] if len(metric_names) == 1 else axes.flatten()\n",
    "\n",
    "    for ax, metric_name in zip(axes, metric_names):\n",
    "        for name, results in experiments.items():\n",
    "            if experiment_names is not None and name not in experiment_names:\n",
    "                continue\n",
    "\n",
    "            ax.plot(config['pixels_allowed'], [e[metric_name][-1] for e in results], label=name, alpha=.7)\n",
    "\n",
    "        if not ax.lines:\n",
    "            print(f\"No data found for metric: {metric_name}\")\n",
    "\n",
    "        ax.set_xlabel('# Pixels Allowed (log scale)')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_title(metric_name.title())\n",
    "        ax.grid()\n",
    "\n",
    "        ax.set_xticks(config['pixels_allowed'])\n",
    "        ax.set_xticklabels(config['pixels_allowed'])\n",
    "        ax.minorticks_off()\n",
    "\n",
    "        if metric_name == 'accuracy':\n",
    "            ax.set_yticks([.1*i for i in range(11)] + [.93])\n",
    "\n",
    "    # only one legend\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(1, 0.6))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Train a simple linear classifier, which we'll later use to find important pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mlp = MLP([config['in_dim'], *config['hidden_dims'], config['out_dim']])\n",
    "\n",
    "history = train(baseline_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does restricting to a random set of pixels do?\n",
    "\n",
    "Train a few baselines restricted to a **random** set of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelMLP(nn.Module):\n",
    "    '''\n",
    "    MLP that only uses a subset of input for prediction.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dims, pixel_indices=None):\n",
    "        super().__init__()\n",
    "        self.pixel_indices = pixel_indices\n",
    "        self.mlp = MLP(dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)[:,self.pixel_indices]\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_pixels in config['pixels_allowed']:\n",
    "    pixel_indices = np.random.permutation(config['in_dim'])[:n_pixels]\n",
    "    dims = [n_pixels, *config['hidden_dims'], config['out_dim']]\n",
    "\n",
    "    pixel_mlp = PixelMLP(dims, pixel_indices)\n",
    "    history = train(pixel_mlp, verbose=False)\n",
    "    experiments['random'].append(history)\n",
    "\n",
    "del pixel_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if you train only on important pixels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to identify important pixels by L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first layer weights\n",
    "weights = baseline_mlp.linear_layers[0].weight.detach()\n",
    "\n",
    "# L2 Norm of weights associated with each pixel\n",
    "weight_norms = (weights**2).sum(axis=0)**.5\n",
    "\n",
    "# sort by weight_magnitudes\n",
    "important_pixels = torch.argsort(weight_norms, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weight_norms.view(28, 28), aspect='auto')\n",
    "plt.colorbar()\n",
    "# plt.title('L2 Norm of First Layer Weights for MLP')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to train models on important pixels and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_pixels in config['pixels_allowed']:\n",
    "    pixel_indices = important_pixels[:n_pixels]\n",
    "    dims = [n_pixels, *config['hidden_dims'], config['out_dim']]\n",
    "\n",
    "    pixel_mlp = PixelMLP(dims, pixel_indices)\n",
    "    history = train(pixel_mlp, verbose=False)\n",
    "    experiments['L2'].append(history)\n",
    "\n",
    "del pixel_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we do even better by identifying \"orthogonal\" important pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_train(\n",
    "    model, verbose=True, optimizer = None, loss_fn = None,\n",
    "    lasso_weight = .05,\n",
    "    lasso_final = config['in_dim'],\n",
    "    warmup_wait=.1,\n",
    "    final_wait=.1,\n",
    "    ):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for step, (x, y) in enumerate(loop(train_loader, config['max_iters'])):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## lasso loss start\n",
    "        norm = model.linear_layers[0].weight.pow(2).sum(dim=0).sqrt()\n",
    "\n",
    "        # pixels to anneal to - redundant, don't care\n",
    "        final_proportion = (config['in_dim']-lasso_final) / config['in_dim']\n",
    "\n",
    "        # anneal between warmup_wait and final_wait\n",
    "        effective_step = step - (config['max_iters'] * warmup_wait)\n",
    "        anneal_duration = config['max_iters'] * (1 - final_wait - warmup_wait)\n",
    "        anneal = max(min(effective_step / anneal_duration, 1), 0) * final_proportion\n",
    "        accept_threshold = norm.quantile(anneal).item()\n",
    "\n",
    "        lasso_loss = torch.clip(norm, 0, accept_threshold).sum() * lasso_weight\n",
    "\n",
    "        loss = loss_fn(model(x), y) + lasso_loss + (lasso_weight * .2 * norm.sum())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (step + 1) % config['eval_iters'] == 0:\n",
    "            metrics = eval(model, loss_fn)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'step {step+1:{len(str(config[\"max_iters\"]))}d}:', end=' ')\n",
    "                print(' | '.join([f\"{metric}: {value:.4f}\" for metric, value in metrics.items()]))\n",
    "\n",
    "            for metric, value in metrics.items():\n",
    "                history[metric].append(value)\n",
    "            \n",
    "            history['steps'].append(step)\n",
    "    return dict(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of sparse annealing, plot important weights by l2 for pixels=16\n",
    "sparse_mlp = MLP([config['in_dim'], *config['hidden_dims'], config['out_dim']])\n",
    "history = sparse_train(sparse_mlp, lasso_final=16)\n",
    "\n",
    "weights = sparse_mlp.linear_layers[0].weight.detach()\n",
    "weight_norms = (weights**2).sum(axis=0)**.5\n",
    "important_pixels = torch.argsort(weight_norms, descending=True)\n",
    "\n",
    "plt.imshow(weight_norms.view(28, 28), aspect='auto')\n",
    "plt.colorbar()\n",
    "# plt.title('L2 Norm of First Layer Weights for Sparse MLP')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_pixels in config['pixels_allowed']:\n",
    "    # train sparse mlp\n",
    "    sparse_mlp = MLP([config['in_dim'], *config['hidden_dims'], config['out_dim']])\n",
    "    sparse_train(sparse_mlp, lasso_final=n_pixels, verbose=False)\n",
    "\n",
    "    # compute important pixels from first layer of sparse mlp\n",
    "    weights = sparse_mlp.linear_layers[0].weight.detach()\n",
    "    weight_norms = (weights**2).sum(axis=0)**.5\n",
    "    important_pixels = torch.argsort(weight_norms, descending=True)\n",
    "\n",
    "    # train pixel mlp\n",
    "    dims = [n_pixels, *config['hidden_dims'], config['out_dim']]\n",
    "    pixel_mlp = PixelMLP(dims, important_pixels[:n_pixels])\n",
    "    history = train(pixel_mlp, verbose=False)\n",
    "    experiments['sparse'].append(history)\n",
    "\n",
    "del pixel_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot mnist examples (via gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_data = datasets.MNIST(root='data/mnist', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_examples(data, examples_per_digit=5):\n",
    "    digits = list(range(10))\n",
    "    fig, axes = plt.subplots(examples_per_digit, len(digits), figsize=(20, 10), dpi=400)\n",
    "    \n",
    "    # fig.suptitle('MNIST Digits', fontsize=16)\n",
    "    \n",
    "    for digit in digits:\n",
    "        digit_indices = [i for i, (img, label) in enumerate(data) if label == digit]\n",
    "        for i in range(examples_per_digit):\n",
    "            ax = axes[i, digit]\n",
    "            img, _ = data[digit_indices[i]]\n",
    "            ax.imshow(img.squeeze(), cmap='gray', interpolation='none')\n",
    "            ax.axis('off')\n",
    "            if i == 0:\n",
    "                ax.set_title(str(digit), fontsize=14)\n",
    "    \n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "plot_mnist_examples(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
